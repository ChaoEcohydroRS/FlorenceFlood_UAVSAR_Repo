{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Apr 26 11:37:49 2020\n",
    "\n",
    "@author: wayne\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "from google.cloud import storage\n",
    "import os\n",
    "#import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function used for uploading\n",
    "def upload_blob(source_file_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "    \n",
    "    #set the target filename saving in the cloud\n",
    "    #os.path.splitext(os.path.basename(source_file_name))[0]\n",
    "    destination_blob_name=os.path.basename(source_file_name)\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucketName)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    To avaid the error of \"ConnectionError: ('Connection aborted.', timeout())\"\n",
    "    https://github.com/googleapis/python-storage/issues/74\n",
    "    # WARNING; WORKAROUND to prevent timeout for files > 6 MB on 800 kbps upload link.\n",
    "    storage.blob._DEFAULT_CHUNKSIZE = 5 * 1024* 1024  # 5 MB\n",
    "\n",
    "    for anyone with an upload speed of at least 1.1 Mbps [1], then no change needs to be made to the library, and only the public setter needs to be used.\n",
    "\n",
    "    For anyone whose upload speed is less than 1.1 Mbps, the module level\n",
    "    storage.blob._MAX_MULTIPART_SIZE = 5 * 1024* 1024 # 5 MB\n",
    "    is still required (in addition to setting blob.chunk_size).\n",
    "    '''\n",
    "\n",
    "    storage.blob._MAX_MULTIPART_SIZE = 4 * 1024* 1024 # 5 MB\n",
    "\n",
    "    blob.chunk_size = 4 * 1024 * 1024 # Set 5 MB blob size\n",
    "    try:\n",
    "        #beginning to upload image\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "    except:\n",
    "      print(\"Something went wrong\")\n",
    "    finally:\n",
    "      print(\"The 'try except' is finished\")\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, destination_blob_name\n",
    "        )\n",
    "    )\n",
    "    return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operating function\n",
    "def _func(workstation,jsonFilePath,UploadingGeoTiffFolderPath,FileNamePrex): \n",
    "    \n",
    "    #set the Authentication parameters\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= \\\n",
    "    jsonFilePath+\"/Upr2020-171ba39e79cc.json\" \n",
    "\n",
    "    global bucketName\n",
    "    bucketName=\"uavsar\"\n",
    "    \n",
    "    #set the path to the data needs to upload\n",
    "    rasterGeotiff_List=[]\n",
    "    \n",
    "    #get all elements of the tif matrix as a list to be applied\n",
    "    os.chdir(UploadingGeoTiffFolderPath)\n",
    "    \n",
    "    \n",
    "    for geotiffFile in glob.glob('*'+FileNamePrex+\"*.tif\"):\n",
    "    #     for geotiffFile in glob.glob('*'+FileNamePrex+\"_D_ani*.tif\"):\n",
    "\n",
    "        \n",
    "        fullFilePath=UploadingGeoTiffFolderPath + '/' + geotiffFile\n",
    "        rasterGeotiff_List.append(fullFilePath)\n",
    "\n",
    "    print(len(rasterGeotiff_List))\n",
    "    \n",
    "    #begin to conduct the operation on each T3 maxtrix element\n",
    "    for rasterName in rasterGeotiff_List:\n",
    "        \n",
    "        #get the source file path waiting for uploading\n",
    "        sourceFileName= rasterName\n",
    "        print(sourceFileName)\n",
    "   \n",
    "        #set the file waiting for uploading\n",
    "        upload_blob(sourceFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workstation: /pine/scr/w/a/wayne128/UAVSAR\n",
      "jsonFilePath: /pine/scr/w/a/wayne128/UAVSAR/JupyterNote/GEE_GCS\n"
     ]
    }
   ],
   "source": [
    "# ### set working directory\n",
    "os.chdir(\"/pine/scr/w/a/wayne128/UAVSAR\")\n",
    "\n",
    "#get current working directory\n",
    "Workstation=os.getcwd()\n",
    "print('Workstation:',Workstation)\n",
    "\n",
    "#set jsonFilePath\n",
    "jsonFilePath=Workstation+'/JupyterNote/GEE_GCS'\n",
    "print('jsonFilePath:',jsonFilePath)\n",
    "\n",
    "#set the path link to geotiff files required to upload\n",
    "UploadingGeoTiffFolderPath=Workstation+'/OutputGeotiff'\n",
    "\n",
    "# UploadingGeoTiffFolderPath=Workstation+'/Decomposition'\n",
    "\n",
    "\n",
    "\n",
    "FileNamePrexList=[\n",
    "#     \"cpfear_35303_18069_004_180923_L090_CX_01\"\n",
    "# \"cpfear_13510_18065_008_180918_L090_CX_01\", \n",
    "# \"cpfear_13510_18067_003_180920_L090_CX_01\",\n",
    "# \"cpfear_13510_18069_005_180923_L090_CX_01\",   \n",
    "    \n",
    "# \"cpfear_13510_18068_003_180922_L090_CX_01\", \n",
    "# \"cpfear_13510_18066_005_180919_L090_CX_01\",\n",
    "\n",
    "# \"cpfear_35303_18065_004_180918_L090_CX_01\", \n",
    "# \"cpfear_35303_18067_002_180920_L090_CX_01\",\n",
    "# \"cpfear_35303_18069_004_180923_L090_CX_01\",\n",
    "    \n",
    "# \"cpfear_35303_18066_002_180919_L090_CX_01\", \n",
    "# \"cpfear_35303_18068_002_180922_L090_CX_01\",\n",
    "\n",
    "# \"lumber_31509_18065_009_180918_L090_CX_01\",\n",
    "# \"lumber_31509_18069_006_180923_L090_CX_01\",\n",
    "    \n",
    "# \"lumber_31509_18066_006_180919_L090_CX_01\",\n",
    "\"lumber_31509_18067_004_180920_L090_CX_01\",\n",
    "# \"lumber_31509_18068_004_180922_L090_CX_01\",\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lumber_31509_18067_004_180920_L090_CX_01\n",
      "1\n",
      "/pine/scr/w/a/wayne128/UAVSAR/OutputGeotiff/lumber_31509_18067_004_180920_L090_CX_01_pauli.tif\n",
      "The 'try except' is finished\n",
      "File /pine/scr/w/a/wayne128/UAVSAR/OutputGeotiff/lumber_31509_18067_004_180920_L090_CX_01_pauli.tif uploaded to lumber_31509_18067_004_180920_L090_CX_01_pauli.tif.\n"
     ]
    }
   ],
   "source": [
    "#     #upload GeoTiff image to GSC\n",
    "#     #turn to the google cloud storage\n",
    "for FileNamePrex in FileNamePrexList:\n",
    "    print(FileNamePrex)\n",
    "    _func(Workstation,jsonFilePath,UploadingGeoTiffFolderPath,FileNamePrex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
